{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMj6SHxcPJR9yliBO3BIgHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CT2020Hypernym/hyponym_and_hyperonym/blob/Maria_spacy/spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsdgWYM0keVL",
        "colab_type": "code",
        "outputId": "422ebbd4-66f8-4ae4-b90a-affc8f8ceb7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install spacy==2.2.3\n",
        "!pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (2.0.3)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.4MB/s \n",
            "\u001b[?25hCollecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (2.21.0)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.17.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (0.9.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (42.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (1.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (1.0.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (8.0.2)\n",
            "Installing collected packages: preshed, blis, thinc, catalogue, spacy\n",
            "  Found existing installation: preshed 2.0.1\n",
            "    Uninstalling preshed-2.0.1:\n",
            "      Successfully uninstalled preshed-2.0.1\n",
            "  Found existing installation: blis 0.2.4\n",
            "    Uninstalling blis-0.2.4:\n",
            "      Successfully uninstalled blis-0.2.4\n",
            "  Found existing installation: thinc 7.0.8\n",
            "    Uninstalling thinc-7.0.8:\n",
            "      Successfully uninstalled thinc-7.0.8\n",
            "  Found existing installation: spacy 2.1.9\n",
            "    Uninstalling spacy-2.1.9:\n",
            "      Successfully uninstalled spacy-2.1.9\n",
            "Successfully installed blis-0.4.1 catalogue-1.0.0 preshed-3.0.2 spacy-2.2.3 thinc-7.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "blis",
                  "preshed",
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.4MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XYP3Jmhl1FN",
        "colab_type": "code",
        "outputId": "67bffdc6-6844-4cab-e806-8dbc9cf0a3d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/buriy/spacy-ru.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'spacy-ru'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 313 (delta 4), reused 7 (delta 2), pack-reused 301\u001b[K\n",
            "Receiving objects: 100% (313/313), 117.34 MiB | 11.80 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLcGO28QmBuB",
        "colab_type": "code",
        "outputId": "650d30b2-a6c1-4e1c-9968-88e6eb5ff823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "import pandas as pd\n",
        "from spacy.util import minibatch, compounding\n",
        "\n",
        "from spacy.lang.ru import Russian\n",
        "\n",
        "n_texts = 65030\n",
        "n_iter = 20\n",
        "\n",
        "def dataParser():\n",
        "  #maybe create new file and work with it\n",
        "  data = pd.read_csv('./pos_hypernymy.csv')\n",
        "  data['coef'] = '1'\n",
        "  data['concat'] = data['child_id'] + ' ' + data['parent_id']\n",
        "  train_pos_df = data[['concat', 'coef']].dropna()\n",
        "  data = pd.read_csv('./neg_hypernymy.csv')\n",
        "  data['coef'] = '1'\n",
        "  data['concat'] = data['child_id'] + ' ' + data['parent_id']\n",
        "  train_neg_df = data[['concat', 'coef']].dropna()\n",
        "  train_df=train_pos_df.append(train_neg_df)\n",
        "\n",
        "  train_df['tuples'] = train_df.apply(\n",
        "      lambda row: (row['concat'],row['coef']), axis=1)\n",
        "  train = train_df['tuples'].tolist()\n",
        "  return train\n",
        "\n",
        "def load_data(limit=0, split=0.8):\n",
        "    train_data = dataParser()\n",
        "    random.shuffle(train_data)\n",
        "    train_data = train_data[-limit:]\n",
        "    texts, labels = zip(*train_data)\n",
        "    cats = [{1: bool(y), 0: not bool(y)} for y in labels]\n",
        "    split = int(len(train_data) * split)\n",
        "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
        "\n",
        "def evaluate(tokenizer, textcat, texts, cats):\n",
        "    docs = (tokenizer(text) for text in texts)\n",
        "    tp = 0.0  # True positives\n",
        "    fp = 1e-8  # False positives\n",
        "    fn = 1e-8  # False negatives\n",
        "    tn = 0.0  # True negatives\n",
        "    for i, doc in enumerate(textcat.pipe(docs)):\n",
        "        gold = cats[i]\n",
        "        for label, score in doc.cats.items():\n",
        "            if label not in gold:\n",
        "                continue\n",
        "            if score >= 0.5 and gold[label] >= 0.5:\n",
        "                tp += 1.0\n",
        "            elif score >= 0.5 and gold[label] < 0.5:\n",
        "                fp += 1.0\n",
        "            elif score < 0.5 and gold[label] < 0.5:\n",
        "                tn += 1\n",
        "            elif score < 0.5 and gold[label] >= 0.5:\n",
        "                fn += 1\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    if (precision + recall) == 0:\n",
        "        f_score = 0.0\n",
        "    else:\n",
        "        f_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #load model (ru)\n",
        "    #nlp = spacy.load('spacy-ru/ru2')\n",
        "    nlp = Russian()\n",
        "    nlp.add_pipe(nlp.create_pipe('sentencizer'), first=True)\n",
        "\n",
        "    if 'textcat' not in nlp.pipe_names:\n",
        "      textcat = nlp.create_pipe('textcat')\n",
        "      nlp.add_pipe(textcat, last=True)\n",
        "    else:\n",
        "      textcat = nlp.get_pipe('textcat')\n",
        "\n",
        "    #categories\n",
        "    textcat.add_label(\"1\") #with hypernymy\n",
        "    textcat.add_label(\"0\") #without\n",
        "\n",
        "    #load dataset\n",
        "\n",
        "    (train_texts, train_cats), (dev_texts, dev_cats) = load_data()\n",
        "    train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
        "    print(\"Using {} examples ({} training, {} evaluation)\"\n",
        "      .format(n_texts, len(train_texts), len(dev_texts)))\n",
        "\n",
        "    #train model\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
        "        optimizer = nlp.begin_training()\n",
        "        print(\"Training the model...\")\n",
        "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
        "        for i in range(n_iter):\n",
        "            losses = {}\n",
        "            # batch up the examples using spaCy's minibatch\n",
        "            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
        "                          losses=losses)\n",
        "            with textcat.model.use_params(optimizer.averages):\n",
        "                # evaluate on the dev data split off in load_data()\n",
        "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
        "            print(\n",
        "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\".format(  # print a simple table\n",
        "                    losses[\"textcat\"],\n",
        "                    scores[\"textcat_p\"],\n",
        "                    scores[\"textcat_r\"],\n",
        "                    scores[\"textcat_f\"],\n",
        "                )\n",
        "            )\n",
        "    print(\"Training the model ended.\")\n",
        "\n",
        "    #save the model\n",
        "    output_dir = %pwd\n",
        "    nlp.to_disk(output_dir)\n",
        "    print(\"Saved model to\", output_dir)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 65030 examples (52024 training, 13006 evaluation)\n",
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n",
            "0.000\t0.000\t0.000\t0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH4Xri6zv0L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iijH3YHa5kS7",
        "colab_type": "code",
        "outputId": "deb27e36-e5a1-4f25-a2fd-cd6c87118963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "!pip install git+https://github.com/aatimofeev/spacy_russian_tokenizer.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/aatimofeev/spacy_russian_tokenizer.git\n",
            "  Cloning https://github.com/aatimofeev/spacy_russian_tokenizer.git to /tmp/pip-req-build-h1phe9nd\n",
            "  Running command git clone -q https://github.com/aatimofeev/spacy_russian_tokenizer.git /tmp/pip-req-build-h1phe9nd\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from spacy-russian-tokenizer==0.1.1) (2.2.3)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (7.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (42.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (1.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (0.9.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (2.21.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->spacy-russian-tokenizer==0.1.1) (1.17.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy->spacy-russian-tokenizer==0.1.1) (4.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->spacy-russian-tokenizer==0.1.1) (1.4.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->spacy-russian-tokenizer==0.1.1) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->spacy-russian-tokenizer==0.1.1) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->spacy-russian-tokenizer==0.1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->spacy-russian-tokenizer==0.1.1) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->spacy-russian-tokenizer==0.1.1) (1.0.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->spacy-russian-tokenizer==0.1.1) (8.0.2)\n",
            "Building wheels for collected packages: spacy-russian-tokenizer\n",
            "  Building wheel for spacy-russian-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-russian-tokenizer: filename=spacy_russian_tokenizer-0.1.1-cp36-none-any.whl size=12674 sha256=738531e500c78af1c42974cf516eddfa40076d469e0a23b54d17cf3e8c7e7a02\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yeur6279/wheels/37/3b/bb/cfe712f7c0b78cd08f4a2ef122d17748baf9d4bebecf2e5a54\n",
            "Successfully built spacy-russian-tokenizer\n",
            "Installing collected packages: spacy-russian-tokenizer\n",
            "Successfully installed spacy-russian-tokenizer-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSVhOwSlLi4t",
        "colab_type": "code",
        "outputId": "5c71189b-baea-4e97-d64a-ff396ebbfdf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/dialogue-evaluation/taxonomy-enrichment.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'taxonomy-enrichment'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 114 (delta 16), reused 33 (delta 6), pack-reused 63\u001b[K\n",
            "Receiving objects: 100% (114/114), 17.72 MiB | 8.04 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7c012930-678f-4464-e7c5-addb7d4e3481",
        "id": "aSGDVvkZ4Mw3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load(\"/content\")\n",
        "df = pd.read_csv(\"./taxonomy-enrichment/data/public_test/nouns_public.tsv\", sep=\"\\t\")\n",
        "#print(df.head())\n",
        "\n",
        "doc = nlp('анкетирование сбор')\n",
        "print(doc.cats)\n",
        "doc = nlp('индиго пигмент')\n",
        "print(doc.cats)\n",
        "doc = nlp('анкетирование медведь')\n",
        "print(doc.cats)\n",
        "\n",
        "#doc.cats.items()\n",
        "\n",
        "#print(df['АБДОМИНОПЛАСТИКА'][0]) #на самом деле подаем слово и его кандидаты, потом их сортируем и берем десять первых\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1': 0.7040451765060425, '0': 0.8136601448059082}\n",
            "{'1': 0.8838895559310913, '0': 0.8772980570793152}\n",
            "{'1': 0.7902513146400452, '0': 0.5155986547470093}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}